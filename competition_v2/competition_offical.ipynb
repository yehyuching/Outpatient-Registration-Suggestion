{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you male or female (male= 1 or female=2) 2\n",
      "小姐您好!\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#compile sym_talk\n",
    "talk_dic ={}\n",
    "f_talk = open('symptom_talks.txt', encoding = 'utf-8')\n",
    "for talk_line in f_talk:  \n",
    "    talk_words = talk_line.replace('\\n', '')\n",
    "    split_talk = talk_words.split(':')\n",
    "    talk_dic[split_talk[0]]=split_talk[1]\n",
    "\n",
    "#compile doc-word\n",
    "f = open('./new_SymptomToOutpatient.txt', encoding = 'utf-8').read()\n",
    "splitF = f.split(':')\n",
    "words = [w.replace('\\n', '') for w in splitF]\n",
    "depgroup =set()\n",
    "for dep in words:\n",
    "    depname = dep.split(',')\n",
    "    depgroup.update(depname[:-1])\n",
    "#print(depgroup)\n",
    "\n",
    "new_f = open('new_SymptomToOutpatient.txt', encoding = 'utf-8')\n",
    "doc_list= []\n",
    "for deps in depgroup: \n",
    "    slist=[]\n",
    "    new_f.seek(0)\n",
    "    for line in new_f:\n",
    "        sym_dep = line.split(\":\")\n",
    "        depset = sym_dep[1].split(\",\")\n",
    "        for dep in depset:\n",
    "            if(dep==deps):\n",
    "                slist.append(sym_dep[0])\n",
    "    joined = \" \".join(slist)\n",
    "    doc_list.append(joined)\n",
    "\n",
    "wf = open('word_doc.txt','w', encoding = 'utf-8')\n",
    "for dw in doc_list:\n",
    "    wf.write(dw + \"\\n\")\n",
    "\n",
    "wf_new = open('word_doc.txt', encoding = 'utf-8')  \n",
    "doccontent=[]\n",
    "for line in wf_new:\n",
    "    line = line.replace(\"\\n\",\"\")\n",
    "    doccontent.append(line)\n",
    "    \n",
    "vectorizer = TfidfVectorizer()                  \n",
    "tfidf = vectorizer.fit_transform(doccontent).toarray()            \n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "sex_answer = input('are you male or female (male= 1 or female=2) ')\n",
    "if sex_answer == \"1\":\n",
    "    sex = \"Male\"\n",
    "    print(\"先生您好!\")\n",
    "if sex_answer == \"2\":\n",
    "    sex = \"Female\" \n",
    "    print(\"小姐您好!\")\n",
    "    \n",
    "test_set=[]\n",
    "first_sym = input('please write the first symptons:')\n",
    "second_sym = input('please write the second symptons:')\n",
    "initial_sym = first_sym + \" \" + second_sym\n",
    "print(\"您的初始症狀是:\" + initial_sym)\n",
    "test_set.append(initial_sym)\n",
    "query_set = []\n",
    "split_sym=test_set[0].split(\" \")\n",
    "for symid in range(len(split_sym)):\n",
    "    query_set.append(split_sym[symid])\n",
    "\n",
    "if sex==\"Female\":\n",
    "    query_set.append(\"睾丸疼痛\")\n",
    "    query_set.append(\"遺精\")\n",
    "else:\n",
    "    query_set.append(\"乳房腫塊\")\n",
    "    query_set.append(\"白帶\")\n",
    "    query_set.append(\"閉經\")\n",
    "    query_set.append(\"痛經\")\n",
    "    query_set.append(\"宮頸糜爛\")\n",
    "    query_set.append(\"流產\")\n",
    "\n",
    "testVectorizerArray = vectorizer.transform(test_set).toarray()\n",
    "cossim = cosine_similarity(testVectorizerArray, tfidf)\n",
    "#print(cossim)\n",
    "\n",
    "nonzero_list = np.nonzero(cossim)\n",
    "argsort = np.argsort(cossim)\n",
    "\n",
    "a = [argsort[0][i] for i in range(len(argsort[0])) if argsort[0][i] in nonzero_list[1]]\n",
    "for i in a:\n",
    "    print(list(depgroup)[i])\n",
    "\n",
    "newlist = []\n",
    "for depid in a:\n",
    "    newlist.append(doccontent[depid])\n",
    "\n",
    "tfvectorizer = TfidfVectorizer()                       \n",
    "X = tfvectorizer.fit_transform(newlist)\n",
    "features = tfvectorizer.get_feature_names()\n",
    "\n",
    "def top_tfidf_feats(row, features, top_n=10):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [features[i] for i in topn_ids]\n",
    "    df = [(features[i], row[i]) for i in topn_ids]\n",
    "    feature_df = pd.DataFrame(df)\n",
    "    feature_df.columns = ['feature', 'tfidf']\n",
    "    print(feature_df)\n",
    "    return top_feats\n",
    "\n",
    "def top_mean_feats(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=10):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.max(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)\n",
    "\n",
    "top_feats = top_mean_feats(X,features, top_n=20)\n",
    "choice = 0\n",
    "answer = \"-1\"\n",
    "if len(a)==1: \n",
    "    choice=6\n",
    "    print(\"recommand:\" + str(list(depgroup)[a[len(a)-1]]) )\n",
    "while(choice<6):\n",
    "    choice +=1\n",
    "    print(\"query_set\" + str(query_set))\n",
    "    if answer==\"1\":\n",
    "        print(\"answer 1\" + test_set[0])\n",
    "        test_set[0] = test_set[0] + \" \" + query\n",
    "        print(\"test_set\" + str(test_set))\n",
    "        # rerun newlist\n",
    "        testVectorizerArray = vectorizer.transform(test_set).toarray()\n",
    "        cossim = cosine_similarity(testVectorizerArray, tfidf)\n",
    "        #print(cossim)\n",
    "        nonzero_list = np.nonzero(cossim)\n",
    "        argsort = np.argsort(cossim)\n",
    "        a = [argsort[0][i] for i in range(len(argsort[0])) if argsort[0][i] in nonzero_list[1]]\n",
    "        for i in a:\n",
    "            print(list(depgroup)[i]) \n",
    "    \n",
    "        newlist = []    \n",
    "        for depid in a:\n",
    "            newlist.append(doccontent[depid])\n",
    "        #print(newlist)\n",
    "        tfvectorizer = TfidfVectorizer()                       \n",
    "        X = tfvectorizer.fit_transform(newlist)\n",
    "        features = tfvectorizer.get_feature_names()\n",
    "        #print('Transform Vectorizer to test set' , str(X.shape))\n",
    "        top_feats = top_mean_feats(X,features, top_n=10)\n",
    "        query = \"\"\n",
    "        for i in range(len(top_feats)):\n",
    "            if(top_feats[i] not in query_set):\n",
    "                query = top_feats[i]\n",
    "                query_talk = talk_dic[query]\n",
    "                query_set.append(top_feats[i])\n",
    "                break\n",
    "     \n",
    "    # check top deps > definded_count --> choice to false\n",
    "    if answer==\"-1\":\n",
    "        print(\"answer -1\")\n",
    "        query = \"\"\n",
    "        # check top deps > definded_count --> choice to false\n",
    "        for i in range(len(top_feats)):\n",
    "            if(top_feats[i] not in query_set):\n",
    "                query = top_feats[i]\n",
    "                query_talk = talk_dic[query]\n",
    "                query_set.append(top_feats[i])\n",
    "                break\n",
    "    answer = input(query_talk+'(1 or -1) ')\n",
    "print(\"recommand:\" + str(list(depgroup)[a[len(a)-1]]) )              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
